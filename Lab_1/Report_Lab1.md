## Report for Lab1

#### Amoiridis Vasileios 8772 & Stefanos Tsoukias 8936

Question no.1

In the file _starter_se.py_ there are several variables that are able to change the parameters of the systems that we simulate in **GEM5**. These variables can be very easily distinguished from the _parser_ function of the same program.

* _--cpu_: this flag defines the type of kernel that we want to use in our simulation. There are 3 choices which are: atomic, minor, hpi.
* _--cpu-freq_: this flag of CPU clock frequency.
* _--num-cores_: this flag defines the number of cores that the CPU is going to use for the execution of the program. If the program has no parallelism, then this number doesn't matter.
* _--mem-type_: this flag defines the type of RAM that we want to use in the simulation.
* _--mem-channels_: this flag defines the number of Channels that the memory consists of.
* _--mem-rank_: this flag defines the rank of the memory.
* _--mem-size_: this flag defines the total size of RAM.

Using these flags we can basically change the characteristics of the system to be simulated, except for its domain frequency. The frequency that is changed using the flag _--cpu-freq_ is the CPU clock frequency and not the system frequency. In order to change the domain frequency which consists of the CPU and the peripherals we need to change the value of _clk_domain.clock_ variable which is in the same file.

Question no.2

Except for _stats.txt_ file, there are also 2 other files that contain valuable information for the system that simulated. These 2 files are _config.ini_ and _config.json_ which contain exactly the same information, just in different formats. The following information are derived from _config.ini_ only because it is in a more readable format.

_Line 44_: **[system.clk_domain]**. The variable _clock_ has a value of 1000. This means that the system domain frequency is 1000000000000 / 1000 = 1GHz. If we changed the clock domain frequency to 2GHz the variable would be equal to 500 instead of 1000.

_Line 58_: **[system.cpu_cluster]**. The variable _clock_ has a value of 250. Respectively this means that the CPU clock is set at 4GHz. Like before if the clock frequency is changed with the flag _--cpu-freq = "5GHz"_ the value would be 200.

_Line 66_: **[system.cpu_cluster.cpus]**. The variable _type_ has a value of "MinorCPU" because we chose the flag _--cpu="minor"_. If we were to choose another arcitecture such as atomic then the variable _type_ would have been "AtomicSimpleCPU". Except for this, if we scroll down in the file we are going to see a lot of variables in different _structs_ with the name _type_ have values derived from MinorCPU when this type of kernel is used. When another type is used then the respective variables change their values in order to match the kernel type. Moreover, the variable _numThreads = 1_ means that we used just one core for our execution.

_Line 1236_: **[system.mem_ctrlsX]**. The variable _ranks_per_channel_ has a value of 2 which is the default value. If we change that through the flag _--mem-rank 4_ then the new value is going to be 4 respectively. If we use the standar _--mem-channels_ value which is 2 then there would be 2 instaces for the channels: _system.mem_ctrls0_ and _system.mem_ctrls1_. Inside both of these structs there is a variable _ranks_per_channel_ obviously. If we were to use more channels then there would be more instances such as _system.mem_ctrls2_, _system.mem_ctrls3_ etc. These can be found inside **[system]** which is in _Line 13_. Moreover, inside this struct we can find the size of the memory that we set with the flag _--mem-size_. The default values is 2GB so if we take a look at variable _system.mem_ctrlsX_, there is a value with the name _range_. This value shows the total size of the memory. 

Last but not least, in order to figure out the Type of RAM that we used for the system, we can take a look at the _.pdf_ or _.svg_ files generated by the simulation. It clearly shows the type of kernel that was used for the simulation and also the type and the channels of RAM that were used.

Question no.3

There 3 different types of CPUs that we can use in the above examples with **gem5**. Their common characteristic is that all of them are in-order CPUs which means that they execute the instructions by the order they arrive to the CPU.

* **Minor CPU**  
The MinorCPU is a flexible in-order processor model which was originally developed to support the Arm ISA, and is applicable to other ISAs as well. MinorCPU has a fixed four-stage in-order execution pipeline, while having configurable data structures and execute behavior. The four-stage pipeline implemented by MinorCPU includes fetching lines, decomposition into macro-ops, decomposi- tion of macro-ops into micro-ops and execute. The basic characteristic of this type of CPU is that it has configurable data structures which helps in build a memory hierarchy in order to better memory access time.

* **AtomicSimple CPU**  
The AtomicSimpleCPU is the version of SimpleCPU that uses atomic memory accesses. It uses the latency estimates from the atomic accesses to estimate overall cache access time. It is basically an uninterruptable read-modify-write memory operation which is requested by the CPU and updates a single value in a specific address.

* **TimingSimple CPU**  
The TimingSimpleCPU is the version of SimpleCPU that uses timing memory accesses. It stalls on cache accesses and waits for the memory system to respond prior to proceeding.

* **HPI CPU**  
High Performance In-Order (HPI) CPU is based on the Arm architecture and is tuned to be representative of a modern in-order Armv8-A implementation. One of its basic characteristics is that it uses the same 4-stage pipeline that is used in the Minor CPU. Moreover, there are separate instruction and data buses, hence an instruction cache (ICache)
and a data cache (DCache). So, there are distinct instruction and data L1 caches backed by a unified L2 cache.

Question no.3a

We write a very simple .c file which just adds all the numbers from 1 to 10,000 and prints the sum of them. 
In order to run an ARM executable file, after we cross-compiled it, we used the command: 
```bash
./build/ARM/gem5.opt -d /home/vamoirid/Desktop/git/Computer-Architecture/Lab_1/MinorCPU_Result ./configs/example/se.py --cpu-type=MinorCPU --caches -c '/home/vamoirid/Desktop/git/Computer-Architecture/Lab_1/testprog_arm' 
```
we run it again for _TimingSimpleCPU_ and save everything in the _TimingSimpleCPU_Result_ folder. All the generated files are located in these two folders (_for better accessibility the 2 stats.txt files are also inside the initial folder Lab_1_).  

One of the most important and interesting results of this simulation is the total number of ticks that elapsed for the program to run on the CPU, and here are the values:

* _MinorCPU_ Kernel Ticks: 184,532,000
* _TimingSimpleCPU_ Kernel Ticks: 389,854,000

Question no.3b

The results show that the Minor kernel is a lot faster than the TimingSimple kernel. This is an expected result because the Minor kernel uses a 4-stage pipeline while TimingSimple doesn't. This means that in Minor kernel while one instruction is processed by the ALU the next one can be fetched.

Question no.3c

As it is requested, in order to see how our system performs with different parameters, the cpu clock-frequency and the type of RAM were modified in order to find out how these two affect the program execution and the overall performance.

For the MinorCPU the total ticks of the CPU with respect to the CPU clock and RAM type are:

|   | LPDDR3_1600_1x32 | DDR3_1600_8x8 | DDR4_2400_8x8 |
|:------:|:-----------:|:-----------:|:-----------:|
| 2.0GHz | 191,091,000 | 184,532,000 | 183,262,000 |
| 2.5GHz | 159,687,600 | 153,259,600 | 152,151,600 |
| 3.0GHz | 138,839,355 | 132,709,491 | 131,277,591 |
| 3.5GHz | 123,842,576 | 117,866,606 | 116,378,834 |
| 4.0GHz | 112,557,000 | 106,028,000 | 105,012,000 |

For the TimingSimpleCPU the total ticks of the CPU with respect to the CPU clock and RAM type are:

|   | LPDDR3_1600_1x32 | DDR3_1600_8x8 | DDR4_2400_8x8 |
|:------:|:-----------:|:-----------:|:-----------:|
| 2.0GHz | 394,541,000 | 389,854,000 | 388,805,000 |
| 2.5GHz | 322,008,000 | 317,202,000 | 316,645,200 |
| 3.0GHz | 273,696,030 | 268,560,171 | 268,214,184 |
| 3.5GHz | 239,280,756 | 234,325,806 | 233,033,944 |
| 4.0GHz | 212,989,000 | 207,634,000 | 207,003,000 |

Some statistics that are generated from these results are
1. MinorCPU is more than twice as fast as TimingSimpleCPU for the same configuration.
2. Upgrading from LPDDR3 to DDR3 for a system with MinorCPU equals an increment in speed of execution of about 4-5% while in TimingSimpleCPU based systems is 1-2.5%.
3. Upgrading from DDR3 to DDR4 for a system with MinorCPU equals an increment in speed of execution of <1% while there is no change in TimingSImpleCPU based system.
4. Upgrading from 2GHz to 2.5GHz equals an increment in speed of execution of 15-16% for MinorCPU based systems while for TimingSimpleCPU based systems the same upgrade equals 18-19% increase.
5. Upgrading from 3.5GHz to 4GHz equals an increment in speed of execution of 8-9% for MinorCPU based systems while for TimingSimpleCPU based systems the same upgrade equals 11.5-12.5% increase.
6. If the CPU clock frequency is doubled from 2GHz to 4GHz in MinorCPU based systems there is an increase in speed of execution of about 42% while in TimingSimpleCPU based systems the increase is almost 47%.
7. Even with the best configuration (--cpu-clock 4GHz --mem-type DDR4_2400_8x8) TimingSimpleCPU is 8% slower than the worst configuration (--cpu-clock 2GHz --mem-type LPDDR3_1600_8x8) MinorCPU.

It is undeniable that MinorCPU is quite faster than TimingSimpleCPU due to the pipeline architecture. While TimingSimpleCPU awaits for the memory to respond in order to fetch the nexr instruction, MinorCPU does it simultaneously when the previous one is in the ALU. Of course having a 4-stage pipeline doesn't mean a 4 times increase in speed because of the fact that fetching, decoding and executing are procedures with different computing times.
